{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8044435,"sourceType":"datasetVersion","datasetId":4743220}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-06T11:08:04.668637Z","iopub.execute_input":"2024-04-06T11:08:04.669532Z","iopub.status.idle":"2024-04-06T11:08:04.673898Z","shell.execute_reply.started":"2024-04-06T11:08:04.669495Z","shell.execute_reply":"2024-04-06T11:08:04.672677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def knn(data, k=5)->torch.Tensor:\n    \"\"\"Construct edge feature for each point\n    Args:\n      point_cloud: (batch_size, num_points, num_dims)\n      k: int number of neighbours\n\n    Returns:\n      idx: shape:(batch_size, num_points, nums_neighours,)\n    \"\"\"\n    dists_matrix = torch.cdist(data, data)\n    #print(dists_matrix.shape)\n    _, idx = dists_matrix.topk(k+1, dim=-1, largest=False)  # +1 the point itself is included\n    return idx[...,1:] # not include the point itself\n\n\n\ndef get_edge_feature(point_cloud, idx=None, k=20,device=\"cpu\"):\n    \"\"\"Construct edge feature for each point\n    Args:\n      point_cloud: (batch_size, num_points, num_dims)\n      idx: (batch_size, num_points, neighbours)\n      k: int\n      device: cpu/cuda\n\n    Returns:\n      features: (batch_size, num_dims ,num_points, k)\n    \"\"\"\n    point_cloud = point_cloud.to(device)\n    batch_size = point_cloud.shape[0]\n    num_points = point_cloud.shape[1]\n\n    if(idx==None):\n        idx = knn(point_cloud,k=k) # (batch_size, num_points, nums_neighours,)\n\n    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1) * num_points # create the base index for mapping\n    idx = idx.to(device=device)\n    idx = idx + idx_base #[0...0...0]->[0...100...200]\n    idx=idx.view(-1) # flatten it -> tensor([  0,  56,  25,  ..., 225, 222, 271], device='cuda:0') e.g: [K01,K02,K03,K11,K12,K13...] shape = (B*N*K) \n   \n    num_dims = point_cloud.shape[2]\n\n    # feature : turn neighbour index in idx to coordinate\n    feature = point_cloud.view(batch_size*num_points, -1)[idx, :] # feature : B*N*F -> BN * F -> (B*N*K) * F\n    # feature : reshape into (Batch_size * Num_points *Nums_neigbours * Features)\n    feature = feature.view(batch_size, num_points, k, num_dims)\n    \n    # pointcloud : create replicate of the self point up to k for matching feature - size B*N*K(repeated)*F \n    point_cloud = point_cloud.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1) \n\n    # feature size B*N*K*F -> B*N*K*2F (feature-x || x)\n    feature = torch.cat((feature-point_cloud, point_cloud), dim=3)\n\n    # (B * 2F * N * K) for later conv each coordinate(F)\n    feature=feature.permute(0,3,1,2).contiguous()\n\n    return feature\n\n# Example usage:\ndata = torch.rand((3,100, 3))  # 100 points in 20D (batch_size, num_points, num_dims)\n#neighbors = knn(data, k=4)\nedges= get_edge_feature(data)\nprint(edges.shape)\nprint(type(edges))","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:08:06.143290Z","iopub.execute_input":"2024-04-06T11:08:06.143673Z","iopub.status.idle":"2024-04-06T11:08:06.290547Z","shell.execute_reply.started":"2024-04-06T11:08:06.143643Z","shell.execute_reply":"2024-04-06T11:08:06.289460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass EdgeConv(nn.Module):\n    def __init__(self, in_channels, out_channels, num_neighbours=20,device=\"cpu\"):\n        \"\"\"Setup EdgeConv\n        Args:\n        in_channels: int\n        out_channels: int\n        num_neighbours: int\n        \"\"\"\n        super(EdgeConv, self).__init__()\n        self.device=device\n        self.k= num_neighbours\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels=in_channels*2, out_channels=out_channels, kernel_size=1, bias=False,device=self.device),\n            nn.BatchNorm2d(out_channels,device=self.device),\n            nn.LeakyReLU(negative_slope=0.2)\n        )\n\n    def forward(self,x):\n        \"\"\"Setup EdgeConv\n        Args:\n        x: shape - (batch_size, num_points, num_dims)\n\n        Returns:\n        features: (batch_size, num_dims, num_points, num_neigbours)\n        \"\"\"\n        x = get_edge_feature(x, k=self.k,device=self.device) #(batch_size, num_points, dim) -> (batch_size, dim*2, num_points ,k)\n        x = self.conv(x)\n        # for each point pick the largest k (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)\n        x = x.max(dim=-1, keepdim=False)[0]\n        x = x.permute(0,2,1).contiguous()\n        return x\n    \n# Example usage:\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndata = torch.rand((3,100, 3))  # 100 points in 20D (batch_size, num_points, num_dims)\nconv = EdgeConv(3, 64,device=device)\nout = conv(data)\nprint(\"out.shape=\", out.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:08:08.783824Z","iopub.execute_input":"2024-04-06T11:08:08.784236Z","iopub.status.idle":"2024-04-06T11:08:09.842881Z","shell.execute_reply.started":"2024-04-06T11:08:08.784196Z","shell.execute_reply":"2024-04-06T11:08:09.841773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DGCNN(nn.Module):\n    def __init__(self, num_neighbours=20,out_channels=40,dropout_rate =0.3,device=\"cpu\"):\n        super(DGCNN,self).__init__()\n        self.inChannels=[3,64,64,128,256]\n        self.edgeConv0 = EdgeConv(in_channels=3,out_channels=64,num_neighbours=num_neighbours,device=device)\n        self.edgeConv1 = EdgeConv(in_channels=64,out_channels=64,num_neighbours=num_neighbours,device=device)\n        self.edgeConv2 = EdgeConv(in_channels=64,out_channels=128,num_neighbours=num_neighbours,device=device)\n        self.edgeConv3 = EdgeConv(in_channels=128,out_channels=256,num_neighbours=num_neighbours,device=device)\n\n        self.edgeConv4 = EdgeConv(in_channels=512,out_channels=1024,num_neighbours=num_neighbours,device=device)\n\n        self.linear1 = nn.Linear(2048, 512, bias=False,device=device)\n        self.bn1 = nn.BatchNorm1d(512,device=device)\n        self.drop1 = nn.Dropout(dropout_rate)\n        self.linear2 = nn.Linear(512, 256, bias=False,device=device)\n        self.bn2 = nn.BatchNorm1d(256,device=device)\n        self.drop2 = nn.Dropout(dropout_rate)\n        self.linear3 = nn.Linear(256,out_channels, bias=False,device=device)\n\n\n    def forward(self,x):\n        x0=self.edgeConv0(x)\n        #print(\"x0:\",x0.shape)\n        x1=self.edgeConv1(x0)\n        x2=self.edgeConv2(x1)\n        x3=self.edgeConv3(x2)\n\n        x=torch.cat((x0,x1,x2,x3),dim=2)\n        \n        x= self.edgeConv4(x) # (batch_size, num_points ,64+64+128+256) -> (batch_size, num_points, emb_dims(1024))\n        \n        #todo \n        # maxpool and avgpool\n        x= x.permute(0,2,1).contiguous()\n        maxPoolX = F.adaptive_avg_pool1d(x,1).view(x.shape[0],-1)\n        avgPoolX = F.adaptive_avg_pool1d(x,1).view(x.shape[0],-1)\n        x=torch.cat((maxPoolX,avgPoolX),1) #(batch_size, 2048)\n        \n        #mlp[512,256,c(40)]\n        x= F.leaky_relu(self.bn1(self.linear1(x)))\n        x=self.drop1(x)\n        x= F.leaky_relu(self.bn2(self.linear2(x)))\n        x=self.drop2(x)\n        x= self.linear3(x)\n        # output\n\n        return x\n    \n# Example usage:\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndata = torch.rand((3,100, 3))  # 100 points in 20D (batch_size, num_points, num_dims)\nprint(\"data shape: \", data.shape)\nprint(device)\ndgcnn = DGCNN(device=device)\nout = dgcnn(data)\n\nprint(\"out.shape=\", out.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:08:11.171126Z","iopub.execute_input":"2024-04-06T11:08:11.171541Z","iopub.status.idle":"2024-04-06T11:08:11.315712Z","shell.execute_reply.started":"2024-04-06T11:08:11.171508Z","shell.execute_reply":"2024-04-06T11:08:11.314715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DGCNN_S(nn.Module):\n    def __init__(self, num_neighbours=10,out_channels=40,device=\"cpu\"):\n        super(DGCNN_S,self).__init__()\n        self.inChannels=[3,64,64,128,256]\n        self.edgeConv0 = EdgeConv(in_channels=3,out_channels=64,num_neighbours=num_neighbours,device=device)\n        self.edgeConv1 = EdgeConv(in_channels=64,out_channels=64,num_neighbours=num_neighbours,device=device)\n        self.edgeConv2 = EdgeConv(in_channels=64,out_channels=128,num_neighbours=num_neighbours,device=device)\n\n        self.edgeConv4 = EdgeConv(in_channels=256,out_channels=512,num_neighbours=num_neighbours,device=device)\n\n        self.linear1 = nn.Linear(512, 256, bias=False,device=device)\n        self.bn1 = nn.BatchNorm1d(256,device=device)\n        self.linear2 = nn.Linear(256,out_channels, bias=False,device=device)\n\n\n    def forward(self,x):\n        x0=self.edgeConv0(x)\n        #print(\"x0:\",x0.shape)\n        x1=self.edgeConv1(x0)\n        x2=self.edgeConv2(x1)\n\n        x=torch.cat((x0,x1,x2),dim=2)\n        \n        x= self.edgeConv4(x) # (batch_size, num_points ,64+64+128+256) -> (batch_size, num_points, emb_dims(1024))\n        \n        #todo \n        # maxpool and avgpool\n        x= x.permute(0,2,1).contiguous()\n        x = F.adaptive_avg_pool1d(x,1).view(x.shape[0],-1)\n        \n        #mlp[512,256,c(40)]\n        x= F.leaky_relu(self.bn1(self.linear1(x)))\n        x= self.linear2(x)\n        # output\n\n        return x\n    \n# Example usage:\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndata = torch.rand((3, 100, 3))  # 100 points in 20D (batch_size, num_points, num_dims)\nprint(\"data shape: \", data.shape)\nprint(device)\ndgcnn = DGCNN_S(device=device)\nout = dgcnn(data)\n\nprint(\"out.shape=\", out.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:08:13.391795Z","iopub.execute_input":"2024-04-06T11:08:13.392452Z","iopub.status.idle":"2024-04-06T11:08:13.441541Z","shell.execute_reply.started":"2024-04-06T11:08:13.392418Z","shell.execute_reply":"2024-04-06T11:08:13.440555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob\nimport h5py\nimport numpy as np\nfrom torch.utils.data import Dataset\n\ndef download_modelnet40():\n    DATA_DIR = 'data'\n    if not os.path.exists(DATA_DIR):\n        os.mkdir(DATA_DIR)\n        www = 'https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip'\n        zipfile = os.path.basename(www)\n        os.system('curl -k -O %s; unzip %s' % (www, zipfile))\n        os.system('mv %s %s' % ('modelnet40_ply_hdf5_2048', DATA_DIR))\n        os.system('rm %s' % (zipfile))\ndef download_modelnet40():\n    BASE_DIR = os.getcwd()\n    DATA_DIR = os.path.join(BASE_DIR, 'data')\n    print(os.path.exists(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048')))\n    if not os.path.exists(DATA_DIR):\n        os.mkdir(DATA_DIR)\n    if not os.path.exists(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048')):\n        www = 'https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip'\n        zipfile = os.path.basename(www)\n        os.system('wget --no-verbose --no-check-certificate %s; unzip %s' % (www, zipfile))\n        os.system('mv %s %s' % ('modelnet40_ply_hdf5_2048', DATA_DIR))\n        os.system('rm %s' % (zipfile))\n\n# def load_data_cls(partition):\n#     download_modelnet40()\n#     BASE_DIR = os.getcwd()\n#     DATA_DIR = os.path.join(BASE_DIR, 'data')\n#     all_data = []\n#     all_label = []\n#     for h5_name in glob.glob(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048', '*%s*.h5'%partition)):\n#         f = h5py.File(h5_name, 'r+')\n#         data = f['data'][:].astype('float32')\n#         label = f['label'][:].astype('int64')\n#         f.close()\n#         all_data.append(data)\n#         all_label.append(label)\n#     all_data = np.concatenate(all_data, axis=0)\n#     all_label = np.concatenate(all_label, axis=0)\n#     return all_data, all_label\n\n# def translate_pointcloud(pointcloud):\n#     xyz1 = np.random.uniform(low=2./3., high=3./2., size=[3])\n#     xyz2 = np.random.uniform(low=-0.2, high=0.2, size=[3])\n       \n#     translated_pointcloud = np.add(np.multiply(pointcloud, xyz1), xyz2).astype('float32')\n#     return translated_pointcloud\ndef load_data_cls():\n    download_modelnet40()\n    BASE_DIR = os.getcwd()\n    DATA_DIR = os.path.join(BASE_DIR, 'data')\n    all_data = []\n    all_label = []\n    for h5_name in glob.glob(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048', '*.h5')):\n        f = h5py.File(h5_name, 'r+')\n        data = f['data'][:].astype('float32')\n        label = f['label'][:].astype('int64')\n        f.close()\n        all_data.append(data)\n        all_label.append(label)\n    all_data = np.concatenate(all_data, axis=0)\n    all_label = np.concatenate(all_label, axis=0)\n    return all_data, all_label\n\ndef translate_pointcloud(pointcloud):\n    xyz1 = np.random.uniform(low=2./3., high=3./2., size=[3])\n    xyz2 = np.random.uniform(low=-0.2, high=0.2, size=[3])\n       \n    translated_pointcloud = np.add(np.multiply(pointcloud, xyz1), xyz2).astype('float32')\n    return translated_pointcloud\n\nclass ModelNet40(Dataset):\n#     def __init__(self, num_points, partition='train'):\n#         self.data, self.label = load_data_cls(partition)\n#         self.num_points = num_points\n#         self.partition = partition        \n\n#     def __getitem__(self, item):\n#         pointcloud = self.data[item][:self.num_points]\n#         label = self.label[item]\n#         if self.partition == 'train':\n#             pointcloud = translate_pointcloud(pointcloud)\n#             np.random.shuffle(pointcloud)\n#         return pointcloud, label\n\n#     def __len__(self):\n#         return self.data.shape[0]\n    def __init__(self, num_points, use_whole_dataset=True):\n        self.data, self.label = load_data_cls()\n        self.num_points = num_points\n        self.use_whole_dataset = use_whole_dataset\n\n    def __getitem__(self, item):\n        pointcloud = self.data[item][:self.num_points]\n        label = self.label[item]\n        if not self.use_whole_dataset:\n            pointcloud = translate_pointcloud(pointcloud)\n            np.random.shuffle(pointcloud)\n        return pointcloud, label\n\n    def __len__(self):\n        return self.data.shape[0]\n    \n# use like this\ndata = ModelNet40(1024)\n_data, label = data[0]\nprint(_data.shape)\nprint(label.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:08:17.622944Z","iopub.execute_input":"2024-04-06T11:08:17.623813Z","iopub.status.idle":"2024-04-06T11:08:20.580679Z","shell.execute_reply.started":"2024-04-06T11:08:17.623775Z","shell.execute_reply":"2024-04-06T11:08:20.579643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\n# PATH = \"/kaggle/input/model2/model.t7\"\n# lr = 0.001\n# num_epochs = 50\n# num_points = 1024\n# batch_size = 8\n# temperature = 2.0\n# apha = 0.5\n# beta = 0.5\n\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# train_loader = DataLoader(ModelNet40(num_points, 'train'), batch_size=batch_size, shuffle=True)\n# test_loader = DataLoader(ModelNet40(num_points, 'test'), batch_size=batch_size, shuffle=False)\n# teacher_model = nn.DataParallel(DGCNN(device=device))\n# teacher_model.load_state_dict(torch.load(PATH,map_location=device))\n# student_model = nn.DataParallel(DGCNN_S(device=device))\n# optimizer = optim.Adam(student_model.parameters(), lr)\n# distillation_loss = KnowledgeDistillationLoss(temperature=temperature)\n\n# best_test_acc = 0\n# for epoch in range(num_epochs):\n#     #train\n#     student_model.train()\n#     total_loss = 0\n#     for data, label in train_loader:\n#         data, label = data.to(device), label.to(device).squeeze()\n#         optimizer.zero_grad()\n#         student_logits = student_model(data)\n#         teacher_logits = teacher_model(data)\n#         loss = apha * distillation_loss(student_logits, teacher_logits) + beta * F.cross_entropy(student_logits, label)\n#         loss.backward()\n#         optimizer.step()\n#         total_loss += loss.item()\n#     print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {total_loss / len(train_loader):.4f}')\n#     #test\n#     student_model.eval()\n#     total = 0\n#     correct = 0\n#     total_loss = 0\n#     with torch.no_grad():\n#         for data, label in test_loader:\n#             data, label = data.to(device), label.to(device).squeeze()\n#             output = student_model(data)\n#             loss = F.cross_entropy(output, label)\n#             total_loss += loss.item()\n#             _, predicted = output.max(1)\n#             total += label.size(0)\n#             correct += predicted.eq(label).sum().item()\n#     test_acc = correct / total\n#     print(f'Epoch {epoch+1}/{num_epochs}, Test Loss: {total_loss / len(test_loader):.4f}, Test Acc: {test_acc:.4f}')\n#     if test_acc >= best_test_acc:\n#         best_test_acc = test_acc\n#         torch.save(student_model.state_dict(), '/kaggle/working/student_model_50.t7')\nPATH_teacher = \"/kaggle/input/model4/model.t7\"\nPATH_student=\"/kaggle/input/model4/student_model_50.t7\"\nnum_points = 1024\nbatch_size = 8\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntest_loader = DataLoader(ModelNet40(num_points), batch_size=batch_size, shuffle=False)\n# teacher_model = nn.DataParallel(DGCNN(device=device))\n# teacher_model.load_state_dict(torch.load(PATH_teacher,map_location=device))\n# teacher_model.to(device)\n# teacher_model.eval()\nstudent_model = nn.DataParallel(DGCNN_S(device=device))\nstudent_model.load_state_dict(torch.load(PATH_student, map_location=device))\nstudent_model.to(device)\nstudent_model.eval()\n\ntotal = 0\ncorrect = 0\ntotal_loss = 0\n\n# with torch.no_grad():\n#     for data, label in test_loader:\n# #         print(\"test\")\n#         data, label = data.to(device), label.to(device).squeeze()\n#         output = student_model(data)\n#         loss = F.cross_entropy(output, label)\n#         total_loss += loss.item()\n#         _, predicted = output.max(1)\n#         total += label.size(0)\n#         correct += predicted.eq(label).sum().item()\n\n# test_acc = correct / total\n# print(f'Test Loss: {total_loss / len(test_loader):.4f}, Test Acc: {test_acc:.4f}')\nnum_classes=40\nclass_correct = [0] * num_classes  # Used to record the correct number of categories for each category\nclass_total = [0] * num_classes  # Used to record the total number of samples for each category\n\nwith torch.no_grad():\n    for data, label in test_loader:\n        data, label = data.to(device), label.to(device).squeeze()\n        output = student_model(data)\n        loss = F.cross_entropy(output, label)\n        total_loss += loss.item()\n        _, predicted = output.max(1)\n        total += label.size(0)\n        correct += predicted.eq(label).sum().item()\n\n        \n        for i in range(label.size(0)):\n            class_correct[label[i]] += predicted[i].eq(label[i]).item()\n            class_total[label[i]] += 1\n\ntest_acc = correct / total\naverage_per_class_acc = sum(class_correct[i] / class_total[i] for i in range(num_classes)) / num_classes\noverall_acc = sum(class_correct) / sum(class_total)\n\nprint(f'Test Loss: {total_loss / len(test_loader):.4f}')\nprint(f'Test Acc: {test_acc:.4f}')\nprint(f'Average Per-Class Acc: {average_per_class_acc:.4f}')\nprint(f'Overall Acc: {overall_acc:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:08:25.282350Z","iopub.execute_input":"2024-04-06T11:08:25.283204Z","iopub.status.idle":"2024-04-06T11:08:39.382476Z","shell.execute_reply.started":"2024-04-06T11:08:25.283162Z","shell.execute_reply":"2024-04-06T11:08:39.381150Z"},"trusted":true},"execution_count":null,"outputs":[]}]}