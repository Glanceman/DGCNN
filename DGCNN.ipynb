{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1575],\n",
      "        [0.1664],\n",
      "        [0.1799],\n",
      "        [0.1943],\n",
      "        [0.2201],\n",
      "        [0.2395],\n",
      "        [0.2549],\n",
      "        [0.2559],\n",
      "        [0.2830],\n",
      "        [0.2897],\n",
      "        [0.2956],\n",
      "        [0.3049],\n",
      "        [0.3057],\n",
      "        [0.3062],\n",
      "        [0.3081],\n",
      "        [0.3238],\n",
      "        [0.3342],\n",
      "        [0.3509],\n",
      "        [0.3552],\n",
      "        [0.3564]])\n",
      "torch.Size([3, 100, 20, 3])\n",
      "tensor([[0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564],\n",
      "        [0.3564, 0.3564, 0.3564]])\n",
      "tensor([[-0.2939, -0.1933, -0.2676],\n",
      "        [-0.1947, -0.2055, -0.3712],\n",
      "        [ 0.3161,  0.0467, -0.3908],\n",
      "        [ 0.4235,  0.3300,  0.0942],\n",
      "        [ 0.1356, -0.0149,  0.6024],\n",
      "        [-0.5454,  0.3924,  0.0057],\n",
      "        [-0.4661,  0.3146,  0.4420],\n",
      "        [-0.2000, -0.3894, -0.5691],\n",
      "        [-0.0568, -0.1367, -0.7802],\n",
      "        [ 0.5135, -0.5756,  0.2559],\n",
      "        [ 0.4542, -0.6939,  0.0111],\n",
      "        [ 0.5055,  0.4825,  0.4937],\n",
      "        [ 0.4751,  0.6909,  0.1798],\n",
      "        [-0.3726, -0.0671, -0.7713],\n",
      "        [-0.4717,  0.6965, -0.1992],\n",
      "        [-0.7245, -0.4590, -0.2991],\n",
      "        [-0.0245, -0.2808,  0.8942],\n",
      "        [-0.0774, -0.3722, -0.9083],\n",
      "        [-0.1335, -0.7994, -0.5798],\n",
      "        [ 0.9007,  0.0750, -0.4279]])\n",
      "torch.Size([3, 6, 100, 20])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "def knn(data, k=5)->torch.Tensor:\n",
    "    \"\"\"Construct edge feature for each point\n",
    "    Args:\n",
    "      point_cloud: (batch_size, num_points, num_dims)\n",
    "      k: int number of neighbours\n",
    "\n",
    "    Returns:\n",
    "      idx: shape:(batch_size, num_points, nums_neighours,)\n",
    "    \"\"\"\n",
    "    dists_matrix = torch.cdist(data, data)\n",
    "    #print(dists_matrix.shape)\n",
    "    _, idx = dists_matrix.topk(k+1, dim=-1, largest=False)  # +1 the point itself is included\n",
    "    return idx[...,1:] # not include the point itself\n",
    "\n",
    "\n",
    "\n",
    "def get_edge_feature(point_cloud, idx=None, k=20,device=\"cpu\"):\n",
    "    \"\"\"Construct edge feature for each point\n",
    "    Args:\n",
    "      point_cloud: (batch_size, num_points, num_dims)\n",
    "      idx: (batch_size, num_points, neighbours)\n",
    "      k: int\n",
    "      device: cpu/cuda\n",
    "\n",
    "    Returns:\n",
    "      features: (batch_size, num_dims ,num_points, k)\n",
    "    \"\"\"\n",
    "    point_cloud = point_cloud.to(device)\n",
    "    batch_size = point_cloud.shape[0]\n",
    "    num_points = point_cloud.shape[1]\n",
    "    num_dims = point_cloud.shape[2]\n",
    "    if(idx==None):\n",
    "        idx = knn(point_cloud,k=k) # (batch_size, num_points, nums_neighours,)\n",
    "\n",
    "    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1) * num_points # create the base index for mapping\n",
    "    idx = idx.to(device=device)\n",
    "    idx = idx + idx_base #[0...0...0]->[0...100...200]\n",
    "    idx=idx.view(-1) # flatten it -> tensor([  0,  56,  25,  ..., 225, 222, 271], device='cuda:0') e.g: [K01,K02,K03,K11,K12,K13...] shape = (B*N*K) \n",
    "   \n",
    "    num_dims = point_cloud.shape[2]\n",
    "\n",
    "    # feature : turn neighbour index in idx to coordinate\n",
    "    feature = point_cloud.view(batch_size*num_points, -1)[idx, :] # feature : B*N*F -> BN * F -> (B*N*K) * F\n",
    "    # feature : reshape into (Batch_size * Num_points *Nums_neigbours * Features)\n",
    "    feature = feature.view(batch_size, num_points, k, num_dims)\n",
    "    \n",
    "    # pointcloud : create replicate of the self point up to k for matching feature - size B*N*K(repeated)*F \n",
    "    point_cloud = point_cloud.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1) \n",
    "\n",
    "    # feature size B*N*K*F -> B*N*K*2F (feature-x || x)\n",
    "    point_To_Neighbour = feature - point_cloud\n",
    "\n",
    "    # Calculate the length (magnitude) of each vector\n",
    "    vector_lengths = torch.norm(point_To_Neighbour, dim=-1,keepdim=True)\n",
    "\n",
    "    max_neighbor_lengths, _ = torch.max(vector_lengths, dim=2, keepdim=True)\n",
    "    max_neighbor_lengths=max_neighbor_lengths.repeat(1, 1, k, num_dims)\n",
    "\n",
    "    normalized_point_To_Neighbour = point_To_Neighbour / max_neighbor_lengths\n",
    "\n",
    "    #feature = torch.cat((normalized_point_To_Neighbour, point_cloud), dim=3)\n",
    "    feature =normalized_point_To_Neighbour\n",
    "\n",
    "    # (B * 2F * N * K) for later conv each coordinate(F)\n",
    "    feature=feature.permute(0,3,1,2).contiguous()\n",
    "\n",
    "    return feature\n",
    "\n",
    "# Example usage:\n",
    "data = torch.rand((3,100, 3))  # 100 points in 20D (batch_size, num_points, num_dims)\n",
    "#neighbors = knn(data, k=4)\n",
    "edges= get_edge_feature(data)\n",
    "print(edges.shape)\n",
    "print(type(edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Edgeconv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2007],\n",
      "        [0.2215],\n",
      "        [0.3034],\n",
      "        [0.3574],\n",
      "        [0.3639],\n",
      "        [0.3702],\n",
      "        [0.3718],\n",
      "        [0.3885],\n",
      "        [0.4165],\n",
      "        [0.4223],\n",
      "        [0.4341],\n",
      "        [0.4560],\n",
      "        [0.4631],\n",
      "        [0.4905],\n",
      "        [0.4973],\n",
      "        [0.5093],\n",
      "        [0.5137],\n",
      "        [0.5161],\n",
      "        [0.5164],\n",
      "        [0.5389]], device='cuda:0')\n",
      "torch.Size([3, 100, 20, 3])\n",
      "tensor([[0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389],\n",
      "        [0.5389, 0.5389, 0.5389]], device='cuda:0')\n",
      "tensor([[ 0.0472, -0.1621,  0.3320],\n",
      "        [-0.3642,  0.1891,  0.0213],\n",
      "        [-0.0937, -0.3833,  0.4015],\n",
      "        [-0.1777, -0.6135,  0.1786],\n",
      "        [-0.5482,  0.3817,  0.0985],\n",
      "        [-0.5625,  0.3864,  0.0778],\n",
      "        [-0.3839, -0.5368,  0.2010],\n",
      "        [-0.4419,  0.3373,  0.4590],\n",
      "        [-0.1527,  0.3459,  0.6740],\n",
      "        [-0.0672, -0.6525,  0.4286],\n",
      "        [-0.6044,  0.3488,  0.4023],\n",
      "        [-0.8132,  0.1894,  0.1364],\n",
      "        [-0.6167, -0.0935,  0.5909],\n",
      "        [-0.8551, -0.1476,  0.2746],\n",
      "        [-0.5326, -0.3263,  0.6793],\n",
      "        [-0.4068, -0.0690,  0.8502],\n",
      "        [-0.0382, -0.0308,  0.9519],\n",
      "        [ 0.0248, -0.1205,  0.9497],\n",
      "        [-0.3051, -0.3530,  0.8370],\n",
      "        [ 0.1992,  0.3352,  0.9208]], device='cuda:0')\n",
      "out.shape= torch.Size([3, 100, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EdgeConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_neighbours=20,device=\"cpu\"):\n",
    "        \"\"\"Setup EdgeConv\n",
    "        Args:\n",
    "        in_channels: int\n",
    "        out_channels: int\n",
    "        num_neighbours: int\n",
    "        \"\"\"\n",
    "        super(EdgeConv, self).__init__()\n",
    "        self.device=device\n",
    "        self.k= num_neighbours\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, bias=False,device=self.device),\n",
    "            nn.BatchNorm2d(out_channels,device=self.device),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"Setup EdgeConv\n",
    "        Args:\n",
    "        x: shape - (batch_size, num_points, num_dims)\n",
    "\n",
    "        Returns:\n",
    "        features: (batch_size, num_dims, num_points, num_neigbours)\n",
    "        \"\"\"\n",
    "        x = get_edge_feature(x, k=self.k,device=self.device) #(batch_size, num_points, dim) -> (batch_size, dim*2, num_points ,k)\n",
    "        x = self.conv(x)\n",
    "        # for each point pick the largest k (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)\n",
    "        x = x.max(dim=-1, keepdim=False)[0]\n",
    "        x = x.permute(0,2,1).contiguous()\n",
    "        return x\n",
    "    \n",
    "# Example usage:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = torch.rand((3,100, 3))  # 100 points in 20D (batch_size, num_points, num_dims)\n",
    "conv = EdgeConv(3, 64,device=device)\n",
    "out = conv(data)\n",
    "print(\"out.shape=\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DGCNN (Classification)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  torch.Size([3, 100, 3])\n",
      "tensor([[0.1738],\n",
      "        [0.1892],\n",
      "        [0.1949],\n",
      "        [0.2607],\n",
      "        [0.2683],\n",
      "        [0.2746],\n",
      "        [0.2822],\n",
      "        [0.2928],\n",
      "        [0.3125],\n",
      "        [0.3244],\n",
      "        [0.3443],\n",
      "        [0.4052],\n",
      "        [0.4271],\n",
      "        [0.4467],\n",
      "        [0.4588],\n",
      "        [0.4680],\n",
      "        [0.4798],\n",
      "        [0.5004],\n",
      "        [0.5250],\n",
      "        [0.5595]], device='cuda:0')\n",
      "torch.Size([3, 100, 20, 3])\n",
      "tensor([[0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595],\n",
      "        [0.5595, 0.5595, 0.5595]], device='cuda:0')\n",
      "tensor([[ 0.1758,  0.1527, -0.2056],\n",
      "        [-0.0172,  0.1182,  0.3163],\n",
      "        [ 0.2058,  0.1639, -0.2282],\n",
      "        [ 0.3192, -0.2900, -0.1767],\n",
      "        [-0.0018,  0.4607,  0.1332],\n",
      "        [ 0.3839, -0.2287,  0.2033],\n",
      "        [ 0.3217,  0.3758, -0.0986],\n",
      "        [ 0.4842, -0.0588, -0.1897],\n",
      "        [ 0.3073,  0.4627, -0.0582],\n",
      "        [ 0.1933,  0.4246,  0.3443],\n",
      "        [ 0.5157, -0.2287, -0.2461],\n",
      "        [ 0.1017,  0.4764,  0.5360],\n",
      "        [ 0.3071,  0.3469,  0.6068],\n",
      "        [ 0.0251,  0.3422,  0.7210],\n",
      "        [ 0.8044,  0.1577, -0.0223],\n",
      "        [ 0.7938, -0.2288,  0.1320],\n",
      "        [ 0.4601,  0.6509,  0.3162],\n",
      "        [ 0.7040,  0.4958, -0.2420],\n",
      "        [ 0.6968, -0.0707,  0.6247],\n",
      "        [ 0.5948,  0.5208,  0.6123]], device='cuda:0')\n",
      "tensor([[2.8079],\n",
      "        [3.0155],\n",
      "        [3.2053],\n",
      "        [3.6909],\n",
      "        [3.7270],\n",
      "        [4.0340],\n",
      "        [4.2936],\n",
      "        [4.3446],\n",
      "        [4.5063],\n",
      "        [5.0113],\n",
      "        [5.6417],\n",
      "        [5.7669],\n",
      "        [5.9780],\n",
      "        [6.0752],\n",
      "        [6.1427],\n",
      "        [6.3743],\n",
      "        [6.5309],\n",
      "        [6.5948],\n",
      "        [6.6243],\n",
      "        [6.7126]], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "torch.Size([3, 100, 20, 64])\n",
      "tensor([[6.7126, 6.7126, 6.7126,  ..., 6.7126, 6.7126, 6.7126],\n",
      "        [6.7126, 6.7126, 6.7126,  ..., 6.7126, 6.7126, 6.7126],\n",
      "        [6.7126, 6.7126, 6.7126,  ..., 6.7126, 6.7126, 6.7126],\n",
      "        ...,\n",
      "        [6.7126, 6.7126, 6.7126,  ..., 6.7126, 6.7126, 6.7126],\n",
      "        [6.7126, 6.7126, 6.7126,  ..., 6.7126, 6.7126, 6.7126],\n",
      "        [6.7126, 6.7126, 6.7126,  ..., 6.7126, 6.7126, 6.7126]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([[-0.0117, -0.0485, -0.0174,  ...,  0.0653, -0.0125,  0.0000],\n",
      "        [-0.0169, -0.0581, -0.0188,  ...,  0.0637, -0.0214,  0.0000],\n",
      "        [-0.0495, -0.0048,  0.1053,  ...,  0.0416,  0.0410,  0.0428],\n",
      "        ...,\n",
      "        [ 0.0613, -0.1678, -0.0186,  ..., -0.0258, -0.1359,  0.0467],\n",
      "        [-0.0487, -0.0659,  0.2264,  ..., -0.0328,  0.0775,  0.1966],\n",
      "        [-0.1380, -0.1529,  0.0093,  ..., -0.0588,  0.0201,  0.1934]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([[4.6398],\n",
      "        [4.9238],\n",
      "        [5.0775],\n",
      "        [5.5835],\n",
      "        [6.0856],\n",
      "        [6.4596],\n",
      "        [6.5364],\n",
      "        [6.8265],\n",
      "        [7.0662],\n",
      "        [7.2463],\n",
      "        [8.4609],\n",
      "        [8.5429],\n",
      "        [8.5986],\n",
      "        [8.8060],\n",
      "        [9.2349],\n",
      "        [9.2784],\n",
      "        [9.3315],\n",
      "        [9.4064],\n",
      "        [9.5693],\n",
      "        [9.7064]], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "torch.Size([3, 100, 20, 128])\n",
      "tensor([[9.7064, 9.7064, 9.7064,  ..., 9.7064, 9.7064, 9.7064],\n",
      "        [9.7064, 9.7064, 9.7064,  ..., 9.7064, 9.7064, 9.7064],\n",
      "        [9.7064, 9.7064, 9.7064,  ..., 9.7064, 9.7064, 9.7064],\n",
      "        ...,\n",
      "        [9.7064, 9.7064, 9.7064,  ..., 9.7064, 9.7064, 9.7064],\n",
      "        [9.7064, 9.7064, 9.7064,  ..., 9.7064, 9.7064, 9.7064],\n",
      "        [9.7064, 9.7064, 9.7064,  ..., 9.7064, 9.7064, 9.7064]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([[-0.0848,  0.0237,  0.0000,  ..., -0.0187,  0.0000, -0.0833],\n",
      "        [-0.0994,  0.0279,  0.0000,  ..., -0.0319,  0.0000, -0.0931],\n",
      "        [-0.0168, -0.0855,  0.0000,  ...,  0.0668,  0.0000, -0.1032],\n",
      "        ...,\n",
      "        [-0.0977, -0.1314,  0.0407,  ..., -0.0436,  0.0000, -0.1058],\n",
      "        [-0.0961, -0.1997,  0.0000,  ..., -0.0009,  0.0000, -0.1058],\n",
      "        [-0.1383, -0.0997,  0.0900,  ..., -0.0217,  0.0220, -0.1058]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([[ 9.1300],\n",
      "        [ 9.6024],\n",
      "        [10.7784],\n",
      "        [10.9043],\n",
      "        [11.0862],\n",
      "        [11.7759],\n",
      "        [12.5700],\n",
      "        [12.8010],\n",
      "        [13.6830],\n",
      "        [13.9764],\n",
      "        [16.8500],\n",
      "        [17.0383],\n",
      "        [17.0425],\n",
      "        [17.1789],\n",
      "        [17.5002],\n",
      "        [17.7747],\n",
      "        [17.8858],\n",
      "        [18.1062],\n",
      "        [18.1134],\n",
      "        [18.2231]], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "torch.Size([3, 100, 20, 448])\n",
      "tensor([[18.2231, 18.2231, 18.2231,  ..., 18.2231, 18.2231, 18.2231],\n",
      "        [18.2231, 18.2231, 18.2231,  ..., 18.2231, 18.2231, 18.2231],\n",
      "        [18.2231, 18.2231, 18.2231,  ..., 18.2231, 18.2231, 18.2231],\n",
      "        ...,\n",
      "        [18.2231, 18.2231, 18.2231,  ..., 18.2231, 18.2231, 18.2231],\n",
      "        [18.2231, 18.2231, 18.2231,  ..., 18.2231, 18.2231, 18.2231],\n",
      "        [18.2231, 18.2231, 18.2231,  ..., 18.2231, 18.2231, 18.2231]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([[-0.0043, -0.0178, -0.0064,  ..., -0.0213,  0.0222,  0.0000],\n",
      "        [-0.0062, -0.0214, -0.0069,  ..., -0.0324,  0.0147,  0.0000],\n",
      "        [-0.0182, -0.0018,  0.0388,  ...,  0.0057,  0.0074,  0.0024],\n",
      "        ...,\n",
      "        [ 0.0397, -0.0208,  0.0445,  ..., -0.0635,  0.0286,  0.0081],\n",
      "        [ 0.0399, -0.0309,  0.0409,  ..., -0.0635,  0.0456,  0.0350],\n",
      "        [ 0.0619, -0.0740,  0.0049,  ..., -0.0635,  0.0410,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "out.shape= torch.Size([3, 40])\n"
     ]
    }
   ],
   "source": [
    "class DGCNN(nn.Module):\n",
    "    def __init__(self, num_neighbours=20,out_channels=40,dropout_rate =0.3,device=\"cpu\"):\n",
    "        super(DGCNN,self).__init__()\n",
    "        self.edgeConv0 = EdgeConv(in_channels=3,out_channels=64,num_neighbours=num_neighbours,device=device)\n",
    "        self.edgeConv2 = EdgeConv(in_channels=64,out_channels=128,num_neighbours=num_neighbours,device=device)\n",
    "        self.edgeConv3 = EdgeConv(in_channels=128,out_channels=256,num_neighbours=num_neighbours,device=device)\n",
    "\n",
    "        self.edgeConv4 = EdgeConv(in_channels=448,out_channels=1024,num_neighbours=num_neighbours,device=device)\n",
    "\n",
    "        self.linear1 = nn.Linear(2048, 512, bias=False,device=device)\n",
    "        self.bn1 = nn.BatchNorm1d(512,device=device)\n",
    "        self.drop1 = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(512, 256, bias=False,device=device)\n",
    "        self.bn2 = nn.BatchNorm1d(256,device=device)\n",
    "        self.drop2 = nn.Dropout(dropout_rate)\n",
    "        self.linear3 = nn.Linear(256,out_channels, bias=False,device=device)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x0=self.edgeConv0(x)\n",
    "        #print(\"x0:\",x0.shape)\n",
    "        #x1=self.edgeConv1(x0)\n",
    "        x2=self.edgeConv2(x0)\n",
    "        x3=self.edgeConv3(x2)\n",
    "\n",
    "        x=torch.cat((x0,x2,x3),dim=2)\n",
    "        \n",
    "        x= self.edgeConv4(x) # (batch_size, num_points ,64+64+128+256) -> (batch_size, num_points, emb_dims(1024))\n",
    "        \n",
    "        #todo \n",
    "        # maxpool and avgpool\n",
    "        x= x.permute(0,2,1).contiguous()\n",
    "        maxPoolX = F.adaptive_avg_pool1d(x,1).view(x.shape[0],-1)\n",
    "        avgPoolX = F.adaptive_avg_pool1d(x,1).view(x.shape[0],-1)\n",
    "        x=torch.cat((maxPoolX,avgPoolX),1) #(batch_size, 2048)\n",
    "        \n",
    "        #mlp[512,256,c(40)]\n",
    "        x= F.leaky_relu(self.bn1(self.linear1(x)))\n",
    "        x=self.drop1(x)\n",
    "        x= F.leaky_relu(self.bn2(self.linear2(x)))\n",
    "        x=self.drop2(x)\n",
    "        x= self.linear3(x)\n",
    "        # output\n",
    "\n",
    "        return x\n",
    "    \n",
    "# Example usage:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = torch.rand((3,100, 3))  # 100 points in 20D (batch_size, num_points, num_dims)\n",
    "print(\"data shape: \", data.shape)\n",
    "dgcnn = DGCNN(device=device)\n",
    "out = dgcnn(data)\n",
    "\n",
    "print(\"out.shape=\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "(1024, 3)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "#todo DataSet -> use mobilenet 40\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def download_modelnet40():\n",
    "    BASE_DIR = os.getcwd()\n",
    "    DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "    print(os.path.exists(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048')))\n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        os.mkdir(DATA_DIR)\n",
    "    if not os.path.exists(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048')):\n",
    "        www = 'https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip'\n",
    "        zipfile = os.path.basename(www)\n",
    "        os.system('wget --no-verbose --no-check-certificate %s; unzip %s' % (www, zipfile))\n",
    "        os.system('mv %s %s' % ('modelnet40_ply_hdf5_2048', DATA_DIR))\n",
    "        os.system('rm %s' % (zipfile))\n",
    "\n",
    "def load_data_cls(partition):\n",
    "    download_modelnet40()\n",
    "    BASE_DIR = os.getcwd()\n",
    "    DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "    all_data = []\n",
    "    all_label = []\n",
    "    for h5_name in glob.glob(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048', '*%s*.h5'%partition)):\n",
    "        f = h5py.File(h5_name, 'r+')\n",
    "        data = f['data'][:].astype('float32')\n",
    "        label = f['label'][:].astype('int64')\n",
    "        f.close()\n",
    "        all_data.append(data)\n",
    "        all_label.append(label)\n",
    "    all_data = np.concatenate(all_data, axis=0)\n",
    "    all_label = np.concatenate(all_label, axis=0)\n",
    "    return all_data, all_label\n",
    "\n",
    "def translate_pointcloud(pointcloud):\n",
    "    xyz1 = np.random.uniform(low=2./3., high=3./2., size=[3])\n",
    "    xyz2 = np.random.uniform(low=-0.2, high=0.2, size=[3])\n",
    "       \n",
    "    translated_pointcloud = np.add(np.multiply(pointcloud, xyz1), xyz2).astype('float32')\n",
    "    return translated_pointcloud\n",
    "\n",
    "class ModelNet40(Dataset):\n",
    "    def __init__(self, num_points, partition='train'):\n",
    "        self.data, self.label = load_data_cls(partition)\n",
    "        self.num_points = num_points\n",
    "        self.partition = partition        \n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        pointcloud = self.data[item][:self.num_points]\n",
    "        label = self.label[item]\n",
    "        if self.partition == 'train':\n",
    "            pointcloud = translate_pointcloud(pointcloud)\n",
    "            np.random.shuffle(pointcloud)\n",
    "        return pointcloud, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "# use like this\n",
    "train = ModelNet40(1024)\n",
    "test = ModelNet40(1024, 'test')\n",
    "data, label = train[0]\n",
    "print(data.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#todo , not finish \n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import sklearn.metrics as metrics\n",
    "def cal_loss(pred, gold, smoothing=True):\n",
    "    ''' Calculate cross entropy loss, apply label smoothing if needed. '''\n",
    "\n",
    "    gold = gold.contiguous().view(-1)\n",
    "\n",
    "    if smoothing:\n",
    "        eps = 0.2\n",
    "        n_class = pred.size(1)\n",
    "\n",
    "        one_hot = torch.zeros_like(pred).scatter(1, gold.view(-1, 1), 1)\n",
    "        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (n_class - 1)\n",
    "        log_prb = F.log_softmax(pred, dim=1)\n",
    "\n",
    "        loss = -(one_hot * log_prb).sum(dim=1).mean()\n",
    "    else:\n",
    "        loss = F.cross_entropy(pred, gold, reduction='mean')\n",
    "\n",
    "    return loss\n",
    "def train(model, epochs, _lr, numPoints,batchSize,device):\n",
    "    \"\"\"train\n",
    "        Args:\n",
    "        model: classifier\n",
    "        dataset: shape(batch_size,nums_point,dimemsion)\n",
    "        optimizerSelect:1 for SGD, 0 for Adam\n",
    "        epochs:train epochs\n",
    "        device:\n",
    "    \"\"\"\n",
    "    train_loader = DataLoader(ModelNet40(partition='train', num_points=numPoints), num_workers=4,\n",
    "                              batch_size=batchSize, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(ModelNet40(partition='test', num_points=numPoints), num_workers=4,\n",
    "                             batch_size=batchSize, shuffle=True, drop_last=False)\n",
    "\n",
    "\n",
    "    #Try to load models\n",
    "    model = nn.DataParallel(model)\n",
    "    opt = optim.Adam(model.parameters(), lr=_lr, weight_decay=1e-4)\n",
    "    scheduler = CosineAnnealingLR(opt, epochs, eta_min=_lr)\n",
    "    criterion = cal_loss\n",
    "    best_test_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        ####################\n",
    "        # Train\n",
    "        ####################\n",
    "        train_loss = 0.0\n",
    "        count = 0.0\n",
    "        model.train()\n",
    "        train_pred = []\n",
    "        train_true = []\n",
    "        for data, label in train_loader:\n",
    "\n",
    "            data, label = data.to(device), label.to(device).squeeze()\n",
    "\n",
    "            batch_size = data.size()[0]\n",
    "            opt.zero_grad()\n",
    "            logits = model(data)\n",
    "            loss = criterion(logits, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            preds = logits.max(dim=1)[1]\n",
    "            count += batch_size\n",
    "            train_loss += loss.item() * batch_size\n",
    "            train_true.append(label.cpu().numpy())\n",
    "            train_pred.append(preds.detach().cpu().numpy())\n",
    "            break\n",
    "        train_true = np.concatenate(train_true)\n",
    "        train_pred = np.concatenate(train_pred)\n",
    "        scheduler.step()\n",
    "        outstr = 'Train %d, loss: %.6f, train acc: %.6f, train avg acc: %.6f' % (epoch,train_loss*1.0/count,metrics.accuracy_score\n",
    "                                                    (train_true, train_pred),metrics.balanced_accuracy_score\n",
    "                                                    (train_true, train_pred))\n",
    "    \n",
    "        print(outstr)\n",
    "\n",
    "        ####################\n",
    "        # Test\n",
    "        ####################\n",
    "        test_loss = 0.0\n",
    "        count = 0.0\n",
    "        model.eval()\n",
    "        test_pred = []\n",
    "        test_true = []\n",
    "        for data, label in test_loader:\n",
    "            data, label = data.to(device), label.to(device).squeeze()\n",
    "            batch_size = data.size()[0]\n",
    "            logits = model(data)\n",
    "            loss = criterion(logits, label)\n",
    "            preds = logits.max(dim=1)[1]\n",
    "            count += batch_size\n",
    "            test_loss += loss.item() * batch_size\n",
    "            test_true.append(label.cpu().numpy())\n",
    "            test_pred.append(preds.detach().cpu().numpy())\n",
    "\n",
    "        test_true = np.concatenate(test_true)\n",
    "        test_pred = np.concatenate(test_pred)\n",
    "        test_acc = metrics.accuracy_score(test_true, test_pred)\n",
    "        avg_per_class_acc = metrics.balanced_accuracy_score(test_true, test_pred)\n",
    "        outstr = 'Test %d, loss: %.6f, test acc: %.6f, test avg acc: %.6f' % (epoch,test_loss*1.0/count,test_acc,avg_per_class_acc)\n",
    "        print(outstr)\n",
    "        if test_acc >= best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            BASE_DIR = os.getcwd()\n",
    "            DATA_DIR = os.path.join(BASE_DIR, 'checkpoints')\n",
    "            if not os.path.exists(DATA_DIR):\n",
    "                os.mkdir(DATA_DIR)\n",
    "                os.mkdir(os.path.join(DATA_DIR, 'models'))\n",
    "            torch.save(model.state_dict(), 'checkpoints/models/model.t7')    \n",
    "    \n",
    "    \n",
    "    return 0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=DGCNN(device=device).to(device)\n",
    "train(model,50,0.001,1024,8,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\Python\\DGCNN\n"
     ]
    }
   ],
   "source": [
    "## Excute DGCNN\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
